---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<h2>Research</h2>
I'm broadly interested in computer vision and machine learning. Much of my research is about 3D vision, graph neural networks, hand-object interaction and robotics.

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2024.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement</a>
      <br>‪Linfang Zheng, <b>Tze Ho Elden Tse</b>, Chen Wang, Yinghan Sun, Hua Chen, Ales Leonardis, Wei Zhang, Hyung Jin Chang
      <br> CVPR, 2024
      <br> 
      <a href="https://arxiv.org/pdf/2404.11139">[pdf]</a>
      <a href="https://github.com/Lynne-Zheng-Linfang/GeoReF">[code]</a>
      <br> We introduce a novel framework for category-level object pose refinement which integrates an HS-layer and learnable affine transformations to enhance the extraction and alignment of geometric information.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICCV2023.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images </a>
      <br>‪<b>Tze Ho Elden Tse</b>, Franziska Mueller, Zhengyang Shen, Danhang Tang, Thabo Beeler, Mingsong Dou, Yinda Zhang, Sasa Petrovic, Hyung Jin Chang, Jonathan Taylor, Bardia Doosti
      <br> ICCV, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2308.11015.pdf">[pdf]</a>
      <a href="https://eldentse.github.io/Spectral-Graphormer/">[webpage]</a>
      <a href="https://github.com/google-research/google-research/tree/master/spectral_graphormer">[code]</a>
      <br> We present a spectral graph-based Transformer framework that reconstructs two high fidelity hands from multi-view RGB images. The proposed framework combines ideas from spectral graph theory and Transformers.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICCV2023_RY.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation</a>
      <br>‪Runyang Feng, Yixing Gao, <b>Tze Ho Elden Tse</b>, Xueqing Ma, Hyung Jin Chang
      <br> ICCV, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2307.16687.pdf">[pdf]</a>
      <a href="">[webpage]</a> 
      <br> We present a diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation problem.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2023.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://frunyang.github.io/TDMI/">Mutual Information-based Temporal Difference Learning for Human Pose Estimation in Video</a>
      <br>‪Runyang Feng, Yixing Gao, Xueqing Ma, <b>Tze Ho Elden Tse</b>, Hyung Jin Chang
      <br> CVPR, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2303.08475.pdf">[pdf]</a>
      <a href="https://frunyang.github.io/TDMI/">[webpage]</a>
      <br> We present a multi-frame human pose estimation framework, which employs temporal differences across frames to model dynamic contexts.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ECCV2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/s2contact/">S$^2$Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning</a>
      <br>‪<b>Tze Ho Elden Tse$^*$</b>, Zhongqun Zhang$^*$, Kwang In Kim, Ales Leonardis, Feng Zheng, Hyung Jin Chang
      <br> ECCV, 2022 
      <br> 
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610561.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/s2contact/">[webpage]</a>
      <br> We propose a semi-supervised framework that learns contact from monocular videos. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/collab-hand-object/">Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution</a>
      <br>‪<b>Tze Ho Elden Tse</b>, Kwang In Kim, Ales Leonardis, Hyung Jin Chang
      <br> CVPR, 2022 
      <br> 
      <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/collab-hand-object/">[webpage]</a>
      <br> We propose a collaborative learning framework which jointly reconstructs hand and object from a single RGB image.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICRA2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">TP-AE: Temporally Primed 6D Object Pose Tracking with Auto-Encoders</a>
      <br>Linfang Zheng, Ales Leonardis, ‪<b>Tze Ho Elden Tse</b>, Nora Horanyi, Wei Zhang, Hua Chen, Hyung Jin Chang
      <br> ICRA, 2022 
      <br> 
      <a href="http://eldentse.github.io/files/ICRA_2022.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> This paper focuses on instance-level 6D object pose tracking. In particular, the targeted scenarios are symmetric and textureless object under occlusion. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICSR2019.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">No Need to Scream: Robust Sound-based Speaker Localisation in Challenging Scenarios</a>
      <br>‪<b>Tze Ho Elden Tse</b>, D. De Martini and L. Marchegiani
      <br> ICSR, 2019
      <br> 
      <a href="http://eldentse.github.io/files/ICSR2019_039_final_v3.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> Master project at Oxford Robotics Institute.
    </td>
  </tr>

</table>