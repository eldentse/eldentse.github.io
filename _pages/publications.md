---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<h2>Research</h2>
I'm broadly interested in computer vision and machine learning. Much of my research is about 3D vision, graph neural networks, hand-object interaction and robotics.

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/paper_challenge_cropped.pdf" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">Visual Intention Grounding for Egocentric Assistants</a>
      <br>‪Pengzhan Sun, Junbin Xiao, <b>Tze Ho Elden Tse</b>, Yicong Li, Arjun Akula, Angela Yao
      <br> arXiv, 2025
      <br> 
      <a href="https://arxiv.org/pdf/2504.13621">[pdf]</a>
      <a href="">[code]</a>
      <a href="">[webpage]</a>
      <br> We introduce the first dataset, named EgoIntention, for egocentric visual intention grounding. We also propose Reason-to-Grounding (RoG) instruction tuning, a model-agnostic training approach to enhance
     MLLMs for egocentric intention grounding.
    </td>
  </tr>


<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/overview-new-bigger-text-et-cropped.jpg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">A Constrained Optimization Approach for Gaussian Splatting from Coarsely-posed Images and Noisy Lidar Point Clouds</a>
      <br>‪Jizong Peng$^*$, <b>Tze Ho Elden Tse$^*$</b>, Kai Xu, Wenchao Gao, Angela Yao
      <br> arXiv, 2025
      <br> 
      <a href="https://arxiv.org/pdf/2504.09129">[pdf]</a>
      <a href="">[code]</a>
      <a href="">[webpage]</a>
      <br> We present a contrained optimization approach for training Gaussian Splatting without COLMAP from multi-modal camera rig.
    </td>
  </tr>


<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/das3r_davis.gif" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">DAS3R: Dynamics-Aware Gaussian Splatting for Static Scene Reconstruction</a>
      <br>‪Kai Xu, <b>Tze Ho Elden Tse</b>, Jizong Peng, Angela Yao
      <br> arXiv, 2024
      <br> 
      <a href="https://arxiv.org/pdf/2412.19584">[pdf]</a>
      <a href="https://github.com/kai422/das3r?tab=readme-ov-file">[code]</a>
      <a href="https://kai422.github.io/DAS3R/">[webpage]</a>
      <br> We present a novel framework for scene decomposition and static background reconstruction from unposed videos.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/WHMR.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">Humans as Checkerboards: Calibrating Camera Motion Scale
for World-Coordinate Human Mesh Recovery</a>
      <br>‪Fengyuan Yang, Kerui Gu, Ha Linh Nguyen, <b>Tze Ho Elden Tse</b>, Angela Yao
      <br> arXiv, 2024
      <br> 
      <a href="https://arxiv.org/pdf/2407.00574">[pdf]</a>
      <a href="https://martayang.github.io/HAC/">[webpage]</a>
      <br> We present an optimization-free scale calibration framework for global human motion recovery. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/AAAI2025.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics</a>
      <br>‪<b>Tze Ho Elden Tse</b>, Runyang Feng, Linfang Zheng, Jiho Park, Yixing Gao, Jihie Kim, Ales Leonardis, Hyung Jin Chang
      <br> AAAI, 2025
      <br> 
      <a href="https://arxiv.org/pdf/2501.07100">[pdf]</a>
      <br> We introduce a collaborative learning framework for 3D hand-object reconstruction and compositional action recognition using superquadrics.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2024.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">GeoReF: Geometric Alignment Across Shape Variation for Category-level Object Pose Refinement</a>
      <br>‪Linfang Zheng, <b>Tze Ho Elden Tse</b>, Chen Wang, Yinghan Sun, Hua Chen, Ales Leonardis, Wei Zhang, Hyung Jin Chang
      <br> CVPR, 2024
      <br> 
      <a href="https://arxiv.org/pdf/2404.11139">[pdf]</a>
      <a href="https://github.com/Lynne-Zheng-Linfang/GeoReF">[code]</a>
      <br> We introduce a novel framework for category-level object pose refinement which integrates an HS-layer and learnable affine transformations to enhance the extraction and alignment of geometric information.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICCV2023.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images </a>
      <br>‪<b>Tze Ho Elden Tse</b>, Franziska Mueller, Zhengyang Shen, Danhang Tang, Thabo Beeler, Mingsong Dou, Yinda Zhang, Sasa Petrovic, Hyung Jin Chang, Jonathan Taylor, Bardia Doosti
      <br> ICCV, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2308.11015.pdf">[pdf]</a>
      <a href="https://eldentse.github.io/Spectral-Graphormer/">[webpage]</a>
      <a href="https://github.com/google-research/google-research/tree/master/spectral_graphormer">[code]</a>
      <br> We present a spectral graph-based Transformer framework that reconstructs two high fidelity hands from multi-view RGB images. The proposed framework combines ideas from spectral graph theory and Transformers.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICCV2023_RY.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">DiffPose: SpatioTemporal Diffusion Model for Video-Based Human Pose Estimation</a>
      <br>‪Runyang Feng, Yixing Gao, <b>Tze Ho Elden Tse</b>, Xueqing Ma, Hyung Jin Chang
      <br> ICCV, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2307.16687.pdf">[pdf]</a>
      <a href="">[webpage]</a> 
      <br> We present a diffusion architecture that formulates video-based human pose estimation as a conditional heatmap generation problem.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2023.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://frunyang.github.io/TDMI/">Mutual Information-based Temporal Difference Learning for Human Pose Estimation in Video</a>
      <br>‪Runyang Feng, Yixing Gao, Xueqing Ma, <b>Tze Ho Elden Tse</b>, Hyung Jin Chang
      <br> CVPR, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2303.08475.pdf">[pdf]</a>
      <a href="https://frunyang.github.io/TDMI/">[webpage]</a>
      <br> We present a multi-frame human pose estimation framework, which employs temporal differences across frames to model dynamic contexts.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ECCV2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/s2contact/">S$^2$Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning</a>
      <br>‪<b>Tze Ho Elden Tse$^*$</b>, Zhongqun Zhang$^*$, Kwang In Kim, Ales Leonardis, Feng Zheng, Hyung Jin Chang
      <br> ECCV, 2022 
      <br> 
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610561.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/s2contact/">[webpage]</a>
      <br> We propose a semi-supervised framework that learns contact from monocular videos. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/collab-hand-object/">Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution</a>
      <br>‪<b>Tze Ho Elden Tse</b>, Kwang In Kim, Ales Leonardis, Hyung Jin Chang
      <br> CVPR, 2022 
      <br> 
      <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/collab-hand-object/">[webpage]</a>
      <br> We propose a collaborative learning framework which jointly reconstructs hand and object from a single RGB image.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICRA2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">TP-AE: Temporally Primed 6D Object Pose Tracking with Auto-Encoders</a>
      <br>Linfang Zheng, Ales Leonardis, ‪<b>Tze Ho Elden Tse</b>, Nora Horanyi, Wei Zhang, Hua Chen, Hyung Jin Chang
      <br> ICRA, 2022 
      <br> 
      <a href="http://eldentse.github.io/files/ICRA_2022.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> This paper focuses on instance-level 6D object pose tracking. In particular, the targeted scenarios are symmetric and textureless object under occlusion. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICSR2019.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">No Need to Scream: Robust Sound-based Speaker Localisation in Challenging Scenarios</a>
      <br>‪<b>Tze Ho Elden Tse</b>, D. De Martini and L. Marchegiani
      <br> ICSR, 2019
      <br> 
      <a href="http://eldentse.github.io/files/ICSR2019_039_final_v3.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> Master project at Oxford Robotics Institute.
    </td>
  </tr>

</table>