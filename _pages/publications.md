---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<h2>Research</h2>
I'm broadly interested in computer vision and machine learning. Much of my research is about 3D vision, graph neural networks, hand-object interaction and robotics.

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2023.jpeg" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/s2contact/">Mutual Information-based Temporal Difference Learning for Human Pose Estimation in Video</a>
      <br>‪Runyang Feng, Yixing Gao, Xueqing Ma, <u>Tze Ho Elden Tse$^*$</u>, Hyung Jin Chang
      <br> CVPR, 2023 
      <br> 
      <a href="https://arxiv.org/pdf/2303.08475.pdf">[pdf]</a>
      <br> In this paper, we present a multi-frame human pose estimation framework, which employs temporal differences across frames to model dynamic contexts.
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ECCV2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/s2contact/">S$^2$Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning</a>
      <br>‪<u>Tze Ho Elden Tse$^*$</u>, Zhongqun Zhang$^*$, Kwang In Kim, Ales Leonardis, Feng Zheng, Hyung Jin Chang
      <br> ECCV, 2022 
      <br> 
      <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136610561.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/s2contact/">[webpage]</a>
      <br> In this paper, we propose a semi-supervised framework that learns contact from monocular videos. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/CVPR2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/collab-hand-object/">Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution</a>
      <br>‪<u>Tze Ho Elden Tse</u>, Kwang In Kim, Ales Leonardis, Hyung Jin Chang
      <br> CVPR, 2022 
      <br> 
      <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://www.youtube.com/watch?v=EaarDZlyYzc&t=1s&ab_channel=HyungJinChang">[video]</a> -->
      <a href="https://eldentse.github.io/collab-hand-object/">[webpage]</a>
      <br> This paper focuses on 3D reconstruction of hand and object from a single RGB image. The proposed framework is based on collaborative learning. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICRA2022.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">TP-AE: Temporally Primed 6D Object Pose Tracking with Auto-Encoders</a>
      <br>Linfang Zheng, Ales Leonardis, ‪<u>Tze Ho Elden Tse</u>, Nora Horanyi, Wei Zhang, Hua Chen, Hyung Jin Chang
      <br> ICRA, 2022 
      <br> 
      <a href="http://eldentse.github.io/files/ICRA_2022.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> This paper focuses on instance-level 6D object pose tracking. In particular, the targeted scenarios are symmetric and textureless object under occlusion. 
    </td>
  </tr>

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="/images/ICSR2019.png" style=" vertical-align:middle" width="200" />
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://eldentse.github.io/publications/">No Need to Scream: Robust Sound-based Speaker Localisation in Challenging Scenarios</a>
      <br>‪<u>Tze Ho Elden Tse</u>, D. De Martini and L. Marchegiani
      <br> ICSR, 2019
      <br> 
      <a href="http://eldentse.github.io/files/ICSR2019_039_final_v3.pdf">[pdf]</a>
      <!-- <a href="https://github.com/apple/ml-gmpi">[code]</a> -->
      <!-- <a href="https://youtu.be/M5OU_fiD3Jk">[video]</a> -->
      <!-- <a href="https://xiaoming-zhao.github.io/projects/gmpi/">[webpage]</a> -->
      <br> Master project at Oxford Robotics Institute.
    </td>
  </tr>

</table>